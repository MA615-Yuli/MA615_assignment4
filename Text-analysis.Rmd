---
title: "Text analysis"
author: "Yuli Jin"
date: "2021/11/24"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning=F,message = F,echo=F,highlight=F)
#knitr::opts_chunk$set(echo = TRUE,out.width="0.9\\linewidth",dev="png",fig.align  = 'center')
knitr::opts_chunk$set(fig.width=6, fig.height=4,fig.align = "center") 
pacman::p_load(
tidyverse,
magrittr,
knitr,
gutenbergr,
tidytext,
sentimentr
)



```

## Task 1 Pick a book

I choose `The Burning Secret` as the my text analysis. This book was written by Zweug, Stefan.

```{r}

# gutenberg_metadata
# gutenberg_works(str_detect(author, "Zweig"))

my_book=gutenberg_download(c(45755))
#write.table(my_book,'testbook2.txt',row.names = F)

```

```{r}
library(tnum)
tnum.authorize("mssp1.bu.edu")
tnum.setSpace("test2")
source("Book2TN-v6A-1.R")

```




```{r}
#mybook<-read_lines('testbook.txt')
mybook<-read.table('testbookv2.txt',header = T)
#tnBooksFromLines(mybook$text, "Zweig/test2")
```

## TASK 2 bag of word analysis

First, I use three types of sentiment analysis methods AFINN, Bing and NRC to plot barplot to compare these methods. From the graph below, the AFINN and Bing method fits better. Most of the polt in `The Burning Secret` is in negative. In this book, While being treated for asthma at a country spa, an American diplomat's lonely 12-year-old son is befriended and infatuated by a suave, mysterious baron. But soon his adored friend heartlessly brushes him aside and turns his seductive attentions to his mother. The boy's jealousy and feelings of betrayal become uncontrollable. The story is set in Austria in the 1920s. That is to say, at the beginning of the book, the sentiment of the book is positive, but soon it converts into negative sentiment. However, it is difficult to identify which of the two methods is better. In the following task, I use Bing method to conduct further analysis.

```{r}
#my_book=mybook
tidy_books <- my_book %>%
  mutate(
    linenumber = row_number(),
    chapter = cumsum(str_detect(text, 
                                regex("^chapter [\\divxlc]", 
                                      ignore_case = TRUE)))) %>%
  unnest_tokens(word, text)
```


```{r}
afinn <- tidy_books %>% 
  inner_join(get_sentiments("afinn")) %>% 
  group_by(index = linenumber %/% 80) %>% 
  summarise(sentiment = sum(value)) %>% 
  mutate(method = "AFINN")

```



```{r}
afinn <- tidy_books %>% 
  inner_join(get_sentiments("afinn")) %>% 
  group_by(index = linenumber %/% 80) %>% 
  summarise(sentiment = sum(value)) %>% 
  mutate(method = "AFINN")

bing_and_nrc <- bind_rows(
  tidy_books %>% 
    inner_join(get_sentiments("bing")) %>%
    mutate(method = "Bing et al."),
  tidy_books %>% 
    inner_join(get_sentiments("nrc") %>% 
                 filter(sentiment %in% c("positive", 
                                         "negative"))
    ) %>%
    mutate(method = "NRC")) %>%
  count(method, index = linenumber %/% 80, sentiment) %>%
  pivot_wider(names_from = sentiment,
              values_from = n,
              values_fill = 0) %>% 
  mutate(sentiment = positive - negative)
```

```{r fig.cap="sentiment plot"}
#
bind_rows(afinn, 
          bing_and_nrc) %>%
  ggplot(aes(index, sentiment, fill = method)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~method, ncol = 1, scales = "free_y")+
  theme_bw()
```

```{r}
bing_word_counts <- tidy_books %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup()
```

```{r fig.width=6, fig.height=2,fig.cap="negative positive words count"}
#
bing_word_counts %>%
  group_by(sentiment) %>%
  slice_max(n, n = 10) %>% 
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(n, word, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(x = "Contribution to sentiment",
       y = NULL)+
  theme_bw()
```

Figure 2 shows negative and positive word count of each word. For the negative chart, dark is the most common words throughout the whole book. Hate and darkness rank the second and third place respectively. For the positive chart, like is the most common words throughout the whole book. Great and good rank the second and third place respectively.


```{r fig.width=6, fig.height=4,fig.cap='word cloud'}
library(wordcloud)

tidy_books %>%
  anti_join(stop_words) %>%
  count(word) %>%
  with(wordcloud(word, n, max.words = 100))
```

Figure 3 displays word cloud which shows the frequency. As we can see, baron, mother, edgar are the most frequency words among all the words. It is reasonable because they are the main characters in that fiction book. In task 3, I will use two of three characters to conduct further analysis.


```{r fig.width=6, fig.height=4,fig.cap="sentiment word cloud"}
#
library(reshape2)

tidy_books %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  acast(word ~ sentiment, value.var = "n", fill = 0) %>%
  comparison.cloud(colors = c("gray20", "gray80"),
                   max.words = 100)
```

Figure 4 generally converts Figure 2's information into word cloud  

## task 3 sentence-level analysis

### tnum

First, I put the book into tnum, the following table shows evidence of my tnum database.

```{r echo=T}
q24<- tnum.query('zweig/test2/heading# has text',max=90)
df24 <- tnum.objectsToDf(q24)
knitr::kable(df24 %>% select(subject:numeric.value)%>% head())
```


```{r echo=T}
q26<- tnum.query('zweig/test2# has text',max=60)
df26 <- tnum.objectsToDf(q26)
df26 %>% select(subject:string.value)%>% head()

```

```{r}
#tnBooksFromLines(time_machine$text, "wells/hw_time_1")
# q20<-tnum.query(query="zweig/test1# has *",max=100000)
# df20 <- tnum.objectsToDf(q20)
# df20 %>% view()
```






```{r}
df27<- tnum.query('zweig/test2/section# has text',max=7000) %>% tnum.objectsToDf()
#df27 %>% view()
book_sentence<-df27 %>% separate(col=subject,
                  into = c("path1", "path2","section","paragraph","sentence"), 
                  sep = "/", 
                  fill = "right") %>% 
  select(section:string.value)

#book_sentence$section<-str_extract_all(book_sentence$section,"\\d+") %>% unlist() %>% as.numeric()
book_sentence<-book_sentence %>% mutate_at(c('section','paragraph','sentence'),~str_extract_all(.,"\\d+") %>% unlist() %>% as.numeric())



sentence_out<-book_sentence %>% dplyr::mutate(sentence_split = get_sentences(string.value))%$%
    sentiment_by(sentence_split, list(section))

plot(sentence_out)

```

### Compare this analysis with the analysis you did in Task TWO

It is difficult to directly compare Sentimentr and Bing's score. Therefore, I apply `scale` function to keep two variable into the same criteria. Then I use ggplot to plot bar plot. From the Figure below, we can see that the trends, say positive and negetive direction, are mainly similar. But the exact number differs from two methods. Generally, sentimentr package is more optimictic than Bing method. 

```{r fig.cap="sentiment comparison"}
new_bing<-tidy_books %>% 
    inner_join(get_sentiments("bing")) %>%
    mutate(method = "Bing et al.") %>% 
    count(method, index = chapter, sentiment) %>%
  pivot_wider(names_from = sentiment,
              values_from = n,
              values_fill = 0) %>% 
  mutate(sentiment = positive - negative)



new_bing2<-new_bing %>% mutate(bing_scale=scale(sentiment)) %>% select(method,index,bing_scale)
colnames(new_bing2)[2]='section'

sentence_out<-sentence_out %>% mutate(sentimentr_scale=scale(ave_sentiment))


sentence_out_2method<-left_join(sentence_out,new_bing2,by='section')%>% select(section,bing_scale,sentimentr_scale)
sentence_out_2method_plot<-sentence_out_2method %>% pivot_longer(cols=c('sentimentr_scale','bing_scale'),names_to = 'sentiment')

sentence_out_2method_plot %>%ggplot(aes(y=value,x=factor(section))) +
  geom_bar(aes(fill=factor(sentiment)),stat='identity',position = "dodge",width = 0.7)+theme_bw()

```

\newpage


### EXTRA CREDIT: character analysis

Baron and Edger are two main character among the fiction book. I Pick these two characters from my book.     
The following table in the count number of times each character appears in each chapter:

```{r}
#theme(legend.key.size = unit(2, 'cm'),legend.title = element_text(size=30),legend.text = element_text(size=30))
book_sentence_indi<-book_sentence %>% mutate(baron=str_match(book_sentence$string.value,regex('([Bb]aron)'))[,1],
                         edgar=str_match(book_sentence$string.value,regex('(Edgar)'))[,1])


score<-book_sentence_indi %>% dplyr::mutate(sentence_split = get_sentences(string.value))%$%
    sentiment_by(sentence_split) %>% `$`(ave_sentiment)

book_sentence_indi$score<-score
re<-book_sentence_indi %>% group_by(section) %>% summarise(baron=sum(baron %>% is.na() %>% `!`()),
                                                       edgar=sum(edgar%>% is.na() %>% `!`()))

#knitr::kable(re,'simple')
re2<-book_sentence_indi %>% group_by(section,paragraph) %>% summarise(
  both_appear=sum(baron %>% is.na() %>% `!`() & edgar%>% is.na() %>% `!`() ))

#re2 %>% filter(both_appear>0)
#knitr::kable(re2 %>% filter(both_appear>0),'simple')
```

chapter    baron   edgar
--------  ------  ------
       1      10       2
       2      22      17
       3      18      16
       4      13      12
       5       9       5
       6      16      18
       7      12      13
       8      15      24
       9      13      19
      10       8      14
      11      10      12
      12       5      18
      13       0      11
      14       1      13
      15       1      14




The following table is the count of number of times both characters appear in the same paragraphs.


 section   paragraph   both_appear
--------  ----------  ------------
       2           4             1
       2          28             1
       2          35             1
       2          36             1
       2          40             1
       3           1             1
       3          16             1
       4           3             1
       4           7             1
       4          11             1
       4          12             1
       4          23             1
       4          28             1
       5           1             1
       6           1             1
       6           3             1
       6          21             1
       7           5             1
       7           7             1
       7           8             1
       7           9             1
       8           1             1
       8           6             1
       8          11             1
       8          29             1
       8          31             1
       8          35             1
       9           2             1
       9          21             1
       9          32             1
       9          41             1
      10          11             1
      11           5             1
      11          16             2


```{r eval=F}


tnum.getDBPathList(taxonomy="subject", levels=2)

#tnBooksFromLines(time_machine$text, "wells/hw_time_1")

q20<-tnum.query(query="zweig/test1# has *",max=100000)
df20 <- tnum.objectsToDf(q20)
df20 %>% view()
q24<- tnum.query('zweig/test1/heading# has *',max=60)
df24 <- tnum.objectsToDf(q24)
df24 %>% view()

q26<- tnum.query('zweig/test1# has text',max=6000)
df26 <- tnum.objectsToDf(q26)
df26 %>% view()


# q24<- tnum.query('wells9/hw9/heading# has *',max=6000)
# df24 <- tnum.objectsToDf(q24)
# 
# q22<-tnum.query('wells9/hw9/heading:0022# has *')
# df22<-tnum.objectsToDf(q22)
# ord_ch1 <-unlist( tnum.query('wells9/hw9/heading:0022# has ordinal') )
# ord_ch2<-unlist(tnum.query('wells9/hw9/heading:0023# has ordinal'))
# 
# q25<-tnum.query('wells9/hw9/heading:0023# has *')
# df25<-tnum.objectsToDf(q25)
#   
# ch1_txt<-tnum.query('wells9/hw9/section:0022/paragraph:0002# has text',max=30)
# ch1_txt_df<-tnum.objectsToDf(ch1_txt)
# ch1_txt_df$string.value
# 
# ch2_txt<-tnum.query('wells9/hw9/section:0022/paragraph:0002/sentence:# has *',max=30)
# 
# ch2_txt_df<-tnum.objectsToDf(ch2_txt)
# ch2_txt_df$string.value
# 
# length(ch2_txt_df$string.value)
# 
# 
# q21<-tnum.query('wells9/hw9/section:0022/paragraph:0001/# has *',max=30)
# df21<-tnum.objectsToDf(q21)
# 
# library(sentimentr)
# 
# my_book$text[105:145] %>% sentiment()
```

